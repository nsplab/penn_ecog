classdef computerPointProcessFilterGrandState < handle
    
    % -------- OVERVIEW -------
    % A point process filter that takes the vector 'n' of outputs of an
    % arbitrary number of neurons [assuming the output of neuron 'i' is a
    % point process with conditional intensity function 
    % lambda_i = exp(c_i + b_i * v_x + a_i * v_y)]
    % and, for all 'i', updates the estimate for the neuron parameters
    % 'a_i', 'b_i', and 'c_i', as well as the position and velocity of the
    % cursor.
    
    % -------- INPUT --------
    % - 'old_neuronParametersHat' should be an 'm x 3' matrix of doubles,
    %   where 'm' is the number of neurons in the ensemble. It should look
    %   like
    %               [ [a_1 b_1 c_1];
    %                 [a_2 b_2 c_2];
    %                      ...
    %                 [a_m b_m c_m] ];
    %
    % - 'old_uHat' should be a '2 x 1' vector.
    % - 'old_pos' should be a '2 x 1' vector.
    % - 'old_cov' should be an '1 x m' list, where the 'i'-th element is a
    %   '7 x 7' covariance matrix of the state [a_i b_i c_i u_x u_y p_x p_y],
    %   where 'u_x' is the intended 'x' velocity, 'u_y' is the intended 'y'
    %   velocity, 'p_x' is the 'x' position of the cursor, and 'p_y' is the
    %   'y' position of the cursor.
    % - 'n' should be a 'm x 1' vector of 0's and 1's.
    % - 'timeBin' should be a positive number.
    % - 'F' should be a '7 x 7' state evolution matrix.
    % - 'Q' should be a '7 x 7' observation covariance matrix. It would be
    %   trivial to allow 'Q' to be different for each neuron, but here we
    %   assume that 'Q' is the same for all of them.
    
    % -------- OUTPUT --------
    % The 'new_' versions of each of the input variables all have the same
    % shape as the 'old_' versions.
    
    properties
        neuronParametersHat
        pos
        uHat
        cov
        neuronCov
        initialCursorCov
        matMap
            % F_neuron
            % F_cursor
            % b_cursor
            % Q_neuron
            % Q_cursor
            
            % F
            % b
            % Q
        timeBin
        timeStep
        covReset
        
        coordinateSystem
        
        discreteStateTransitions
        initialDiscreteStateProbDist
        
        oldDiscreteStateProbDist
        oldContinuousStateMean
        oldContinuousStateCov
    end
    
    methods
        function obj = computerPointProcessFilterGrandState(parMap)
            if(nargin < 1)
                parMap = parameters();
            end
            
            obj.neuronParametersHat = ...
                generateNeuralParameters(parMap('nNeurons'), ...
                parMap('magnitudeGeneration'), parMap('directionGeneration'), ...
                parMap('baseFactor'), parMap('maxFactor'), parMap('dirList'));
            obj.coordinateSystem = parMap('ppfCoordinateSystem');
            if(strcmp(obj.coordinateSystem, 'polar'))
                obj.neuronParametersHat = ...
                    polarizePars(obj.neuronParametersHat);
            end
            
            obj.pos = [0; 0];
            obj.uHat = [0; 0];
            obj.neuronCov = parMap('neuronCov');
            obj.initialCursorCov = parMap('cursorCov');
            % obj.cursorCov = parMap('cursorCov');
            
            obj.matMap = containers.Map();
            obj.matMap('F_neuron') = parMap('F_neuron');
            obj.matMap('Q_neuron') = parMap('Q_neuron');
            if(strcmp(parMap('computerPrior'), 'undirected'))
                obj.matMap('F_cursor') = parMap('F_cursorUndirected');
                obj.matMap('b_cursor') = parMap('b_cursorUndirected');
                obj.matMap('Q_cursor') = parMap('Q_cursorUndirected');
            elseif(strcmp(parMap('computerPrior'), 'directed'))
                obj.matMap('F_cursor') = parMap('F_cursorDirected');
                obj.matMap('b_cursor') = parMap('b_cursorDirected');
                obj.matMap('Q_cursor') = parMap('Q_cursorDirected');
            end
            
            nNeurons = length(obj.neuronParametersHat(:, 1));
            
            if(ndims(obj.matMap('F_cursor')) == 2)
                F = obj.matMap('F_cursor');
                for neuron = 1:nNeurons
                    F = blkdiag(obj.matMap('F_neuron'), F);
                end
                obj.matMap('F') = F;
            elseif(ndims(obj.matMap('F_cursor')) == 3)
                F = zeros(3 * nNeurons + 4, 3 * nNeurons + 4, ...
                    parMap('maxTrialLength'));
                F_cursor = obj.matMap('F_cursor');
                for t = 1:parMap('maxTrialLength')
                    F_temp = F_cursor(:, :, t);
                    for neuron = 1:nNeurons
                        F_temp = blkdiag(obj.matMap('F_neuron'), F_temp);
                    end
                    F(:, :, t) = F_temp;
                end
                obj.matMap('F') = F;
            end
            
            if(ndims(obj.matMap('Q_cursor')) == 2)
                Q = obj.matMap('Q_cursor');
                for neuron = 1:nNeurons
                    Q = blkdiag(obj.matMap('Q_neuron'), Q);
                end
                obj.matMap('Q') = Q;
            elseif(ndims(obj.matMap('Q_cursor')) == 3)
                Q = zeros(3 * nNeurons + 4, 3 * nNeurons + 4, ...
                    parMap('maxTrialLength'));
                Q_cursor = obj.matMap('Q_cursor');
                for t = 1:parMap('maxTrialLength')
                    Q_temp = Q_cursor(:, :, t);
                    for neuron = 1:nNeurons
                        Q_temp = blkdiag(obj.matMap('Q_neuron'), Q_temp);
                    end
                    Q(:, :, t) = Q_temp;
                end
                obj.matMap('Q') = Q;
            end
            
            b = [repmat(zeros(3, 1), nNeurons, 1); obj.matMap('b_cursor')];
            obj.matMap('b') = b;
            
            obj.cov = obj.initialCursorCov;
            for neuron = 1:nNeurons
                obj.cov = blkdiag(obj.neuronCov{neuron}, obj.cov);
            end
            
            obj.timeBin = parMap('timeBin');
            obj.timeStep = 0;
            obj.covReset = parMap('covReset');
            
            flatten = @(x)x(:);
            
            obj.discreteStateTransitions = ...
                parMap('discreteStateTransitions');
            obj.initialDiscreteStateProbDist = ...
                parMap('initialDiscreteStateProbDist');
            obj.oldDiscreteStateProbDist = ...
                obj.initialDiscreteStateProbDist;
            obj.oldContinuousStateMean = repmat( ...
               [feval(flatten, obj.neuronParametersHat'); obj.pos; ...
               obj.uHat], 1, 2);
            obj.oldContinuousStateCov = repmat(obj.cov, [1 1 2]);
        end
        
        function [pred_x, pred_cov] = predictedProbDist(this)
            flatten = @(x)x(:);
            x = [feval(flatten, this.neuronParametersHat'); this.pos; ...
                this.uHat];
            
            F = this.matrixValue('F');
            Q = this.matrixValue('Q');
            b = this.matrixValue('b');
            
            pred_x = F * x + b;
            pred_cov = F * this.cov * F' + Q;
        end
        
        function [new_x, new_cov] = filter(this, observations, x, cov)
            this.timeStep = this.timeStep + 1;
            
            % I. INITIALIZE THE STATE VECTOR
            % This makes 'x' a vector that contains the parameters of each
            % neuron, sequentially, as well as the position and estimated
            % velocity of the cursor.
             flatten = @(x)x(:);
             x = [feval(flatten, this.neuronParametersHat'); this.pos; ...
                 this.uHat];
            
            % II. FORM THE STATE EVOLUTION MATRICES AND COVARIANCE MATRIX
            nNeurons = length(this.neuronParametersHat(:, 1));
            
            F = this.matrixValue('F');
            Q = this.matrixValue('Q');
            
            b = this.matrixValue('b');
            
            % III. PERFORM THE PREDICTION STEP
            pred_x = F * x + b;
            pred_cov = F * this.cov * F' + Q;

            % IV. PERFORM THE UPDATE STEP
            % First, we calculate values for some of the terms in the
            % update equations.

            % Lambda values, evaluated at 'pred_x'.
            lambdas = exp(this.neuronParametersHat * ...
                [pred_x(end - 1:end); 1]);
            
            % An array, where the '(i,j)'-th entry contains the
            % gradient of log(lambda_j) = c_j + b_j * u_y + a_j * u_x
            % with respect to the state x(i), evaluated at pred_x(i).    
            G_lambda = zeros(length(x), nNeurons);
            
            for neuron = 1:nNeurons
                if(strcmp(this.coordinateSystem, 'polar'))
                    G_lambda(3 * (neuron - 1) + 1, neuron) = ...
                        cos(pred_x(3 * (neuron - 1) + 2)) * pred_x(end - 1) + ...
                        sin(pred_x(3 * (neuron - 1) + 2)) * pred_x(end);
                    G_lambda(3 * (neuron - 1) + 2, neuron) = ...
                        -pred_x(3 * (neuron - 1) + 1) * sin(pred_x(3 * (neuron - 1) + 2)) * pred_x(end - 1) + ...
                        pred_x(3 * (neuron - 1) + 1) * cos(pred_x(3 * (neuron - 1) + 2)) * pred_x(end);
                    G_lambda(3 * neuron, neuron) = 1;

                    G_lambda(end - 1, neuron) = ...
                        pred_x(3 * (neuron - 1) + 1) * cos(pred_x(3 * (neuron - 1) + 2));
                    G_lambda(end, neuron) = ...
                        pred_x(3 * (neuron - 1) + 1) * sin(pred_x(3 * (neuron - 1) + 2));
                elseif(strcmp(this.coordinateSystem, 'cartesian'))
                    G_lambda(3 * (neuron - 1) + 1, neuron) = pred_x(end - 1);
                    G_lambda(3 * (neuron - 1) + 2, neuron) = pred_x(end);
                    G_lambda(3 * neuron, neuron) = 1;

                    G_lambda(end - 1, neuron) = pred_x(3 * (neuron - 1) + 1);
                    G_lambda(end, neuron) = pred_x(3 * (neuron - 1) + 2);
                end
            end
            
            GG_lambda = cell(nNeurons, 1);
            
            for neuron = 1:nNeurons 
                GG_lambda{neuron} = zeros(length(x));
                
                if(strcmp(this.coordinateSystem, 'polar'))
                    GG_lambda{neuron}(3 * (neuron - 1) + 1, 3 * (neuron - 1) + 2) = ...
                        -sin(pred_x(3 * (neuron - 1) + 2)) * pred_x(end - 1) + ...
                        cos(pred_x(3 * (neuron - 1) + 2)) * pred_x(end);
                    GG_lambda{neuron}(3 * (neuron - 1) + 2, 3 * (neuron - 1) + 1) = ...
                        -sin(pred_x(3 * (neuron - 1) + 2)) * pred_x(end - 1) + ...
                        cos(pred_x(3 * (neuron - 1) + 2)) * pred_x(end);
                    GG_lambda{neuron}(3 * (neuron - 1) + 2, 3 * (neuron - 1) + 2) = ...
                        -pred_x(3 * (neuron - 1) + 1) * cos(pred_x(3 * (neuron - 1) + 2)) * pred_x(end - 1) - ...
                        pred_x(3 * (neuron - 1) + 1) * sin(pred_x(3 * (neuron - 1) + 2)) * pred_x(end);
                    GG_lambda{neuron}(3 * (neuron - 1) + 1, end - 1) = ...
                        cos(pred_x(3 * (neuron - 1) + 2));
                    GG_lambda{neuron}(end - 1, 3 * (neuron - 1) + 1) = ...
                        cos(pred_x(3 * (neuron - 1) + 2));
                    GG_lambda{neuron}(3 * (neuron - 1) + 1, end) = ...
                        sin(pred_x(3 * (neuron - 1) + 2));
                    GG_lambda{neuron}(end, 3 * (neuron - 1) + 1) = ...
                        sin(pred_x(3 * (neuron - 1) + 2));
                    GG_lambda{neuron}(3 * (neuron - 1) + 2, end - 1) = ...
                        -pred_x(3 * (neuron - 1) + 1) * sin(pred_x(3 * (neuron - 1) + 2));
                    GG_lambda{neuron}(end - 1, 3 * (neuron - 1) + 2) = ...
                        -pred_x(3 * (neuron - 1) + 1) * sin(pred_x(3 * (neuron - 1) + 2));
                    GG_lambda{neuron}(3 * (neuron - 1) + 2, end) = ...
                        -pred_x(3 * (neuron - 1) + 1) * cos(pred_x(3 * (neuron - 1) + 2));
                    GG_lambda{neuron}(end, 3 * (neuron - 1) + 2) = ...
                        -pred_x(3 * (neuron - 1) + 1) * cos(pred_x(3 * (neuron - 1) + 2));
                elseif(strcmp(this.coordinateSystem, 'cartesian'))
                    GG_lambda{neuron}(3 * (neuron - 1) + 1, end - 1) = 1;
                    GG_lambda{neuron}(3 * (neuron - 1) + 2, end) = 1;
                    GG_lambda{neuron}(end - 1, 3 * (neuron - 1) + 1) = 1;
                    GG_lambda{neuron}(end, 3 * (neuron - 1) + 2) = 1;
                end
            end

            % The gradient of log(lambda_j) = c_j + b_j * u_y + a_j * u_x
            % with respect to x(i)', and the gradient of that with
            % respect to x(i), evaluated at pred_x(i). 
            % GG_lambda = this.GG_lambda;

            % 'cov_adjust' is the difference between the updated value
            % of the covariance and the predicted value of the
            % covariance.
            cov_adjust = zeros(size(pred_cov));
            for neuron = 1:nNeurons
                term = G_lambda(:, neuron) * lambdas(neuron) * ...
                    this.timeBin * G_lambda(:, neuron)' - ...
                    (observations(neuron) - lambdas(neuron) * ...
                    this.timeBin) * GG_lambda{neuron};
                cov_adjust = cov_adjust + term;
            end
                        
            new_cov_inv = inv(pred_cov) + cov_adjust;
            % If new_cov_inv is not nicely invertible, just use
            % pred_cov(i) as estimate for new_cov(i).
            if rcond(new_cov_inv) > 1e-8
                new_cov = inv(new_cov_inv);
            else
                new_cov = pred_cov;
            end

            innovation = zeros(size(x));
            for neuron = 1:nNeurons
                innovation = innovation + G_lambda(:, neuron) * ...
                    (observations(neuron) - lambdas(neuron) * this.timeBin);
            end
            new_x = pred_x + new_cov * innovation;
            
            % V. UPDATE THE CLASS PROPERTIES
%             this.neuronParametersHat = ...
%                 reshape(new_x(1:3 * nNeurons), 3, nNeurons)';
%             this.pos = [new_x(end - 3); new_x(end - 2)];
%             this.uHat = [new_x(end - 1); new_x(end)];
%             if(strcmp(this.covReset, 'no'))
%                 this.cov = new_cov;
%             elseif(strcmp(this.covReset, 'yes'))
%                 this.cov = ...
%                     blkdiag(new_cov(1:3 * nNeurons, 1:3 * nNeurons), ...
%                     this.initialCursorCov);
%             end
%             for neuron = 1:nNeurons
%                 this.neuronCov{neuron} = ...
%                     new_cov(3 * (neuron - 1) + 1:3 * neuron, ...
%                     3 * (neuron - 1) + 1:3 * neuron);
%             end
        end
        
        % Variable names correspond to the steps of the algorithm given on
        % p. 8 of "Breaking the fixed-arrival-time restriction in reaching
        % movements of neural prosthetic devices". This is because writing
        % out variable names in terms of conditional probabilities looks
        % terrible and isn't very informative.
        function pred_x = update(this, observations)
            % This '2 x 2' matrix is
            %     [ [a(0, 0) a(0, 1)]
            %       [a(1, 0) a(1, 1)] ],
            % where
            %     a(m,n) = ...
            %         p(new_s == m | old_s == n) * p(old_s == n | prev_obs)
            % It is used to simplify calculations in steps 1 and 2.
            tempMat= this.discreteStateTransitions .* ...
                repmat(this.oldDiscreteStateProbDist', 2, 1);
%             if(~isnan(tempMat))
%                 tempMat
%             end
            
            % Step 1: This is the probability distribution on 'new_s' given
            % the previous observations. 
            %     step1(1) = p(new_s = 0 | prev_obs),
            %     step1(2) = p(new_s = 1 | prev_obs).
            step1 = sum(tempMat, 1);
%             if(~isnan(step1))
%                 step1
%             end

            % Step 2: This is the probability distribution on 'old_s' given
            % 'new_s' and the previous observations. It is a '2 x 2' matrix
            %     [ [b(0, 0) b(0, 1)]
            %       [b(1, 0) b(1, 1)] ],
            % where
            %     b(m,n) = p(old_s == n | new_s == m, prev_obs).
            step2 = tempMat ./ repmat(step1, 2, 1);
%             if(~isnan(step2))
%                 step2
%             end
            
            % Step 3: This is a Gaussian approximation to the probability
            % distribution on the old state given a value for 'new_s' and
            % the previous observations.
            mu1 = this.oldContinuousStateMean(:, 1);
            mu2 = this.oldContinuousStateMean(:, 2);
            W1 = this.oldContinuousStateCov(:, :, 1);
            W2 = this.oldContinuousStateCov(:, :, 2);
            
%             step3means = [step2(1, 1) * mu1 + step2(2, 1) * mu2, ...
%                           step2(1, 2) * mu1 + step2(2, 2) * mu2];
                      
            step3means = this.oldContinuousStateMean;
            
%            step3covs = zeros(size(this.oldContinuousStateMean, 1));
%             step3covs(:, :, 1) = ...
%                 step2(1, 1) * (W1 + (mu1 - step3means(:, 1)) * (mu1 - step3means(:, 1))') + ... 
%                 step2(1, 2) * (W2 + (mu2 - step3means(:, 1)) * (mu2 - step3means(:, 1))');
%             step3covs(:, :, 2) = ...
%                 step2(2, 1) * (W1 + (mu1 - step3means(:, 2)) * (mu1 - step3means(:, 2))') + ... 
%                 step2(2, 2) * (W2 + (mu2 - step3means(:, 2)) * (mu2 - step3means(:, 2))');
            
            step3covs = this.oldContinuousStateCov;
            
%             if(~isnan(step3means))
%                 step3means
%             end

            % Step 4: This is a Gaussian approximation to the probability
            % distribution on the new state given a value for 'new_s', the
            % new observation, and all the previous observations.
%             tempMean = step3means(:, 1);
%             tempCov = step3covs(:, :, 1);
%             step4means(:, 1) = [tempMean(1:end - 2); 0; 0];
%             step4covs(:, :, 1) = ...
%                 blkdiag(tempCov(1:end - 2, 1:end - 2), this.initialCursorCov(end - 1:end, end - 1:end)); %blkdiag(tempCov(1:end - 2, 1:end - 2), zeros(2));
            
            [step4means(:, 2), step4covs(:, :, 2)] = ...
                this.filter(observations, step3means(:, 2), step3covs(:, :, 2));
            step4means(:, 1) = step4means(:, 2);
            step4covs(:, 1) = step4means(:, 2);
            
            % Step 5: This is the probability of receiving our new
            % observation vector given a value for 'new_s' and all the
            % previous observations.
            step5 = zeros(2, 1);
            
            lambdas1 = exp(this.neuronParametersHat * [0; 0; 1]);
%            step5(1) = abs(prod(~observations - lambdas1));
             step5(1) = prod(exp(observations .* log(lambdas1 * this.timeBin) - lambdas1 * this.timeBin));
            % NOTE: If one of the base firing rates is greater than 1 /
            % timeBin, then the probability will come out to be 0. With a
            % time bin width of 1 / 30 and accurate base firing rates, this
            % should never happen.
            
            [pred_x, pred_cov] = this.predictedProbDist();
            lambdas2 = exp(this.neuronParametersHat * ...
                [pred_x(end - 1:end); 1]);
            
            magnitude = @(mat)sqrt(sum(mat(:).^2));
%            step5(2) = abs(prod(~observations - lambdas2));
            step5(2) = ...
                sqrt(feval(magnitude, step4covs(:, :, 2)) / feval(magnitude, pred_cov)) * ...
                prod(exp(observations .* log(lambdas2 * this.timeBin) - lambdas2 * this.timeBin));
            
%             if(~isnan(step5))
%                 lambdas1 - lambdas2
%                 sqrt(feval(magnitude, step4covs(:, :, 2)) / feval(magnitude, pred_cov))
%                 step5
%             end

            % Step 6: This is the probability distribution on 'new_s' given
            % the new observation and all previous observations.
            step6 = step5 .* step1' / sum(step5 .* step1');
            
            if(step6(2) > 0.999)
                step6(2) = 0.999;
                step6(1) = 1 - step6(2);
            end
    
            % Step 7: This is modified from the paper. Rather than updating
            % the state of the PPF based on the probability distribution of
            % the continuous state, we instead take the more likely of the
            % two discrete states as the actual discrete state and update
            % the state of the PPF based on that.
            %if(step6(1) > 0.8)
                % If this ends the trial, then we don't actually have to
                % worry about what happens here, but if not, there are a
                % number of things we can do. For the kinematic terms, the
                % obvious choice is to reduce intended velocity to 0 and to
                % keep the position constant. For the neuron parameters, it
                % seems that this would actually give us some information
                % about the baseline firing rate, but we have to run the
                % information through the PPF to actual get a new estimate.
                % I guess we just leave that constant then. Which means we
                % leave the same continuous state mean and covariance as
                % before, only with the velocity mean zeroed out (assuming
                % that a covariance reset is occuring, so that the
                % covariance on the velocity remains the same).
                
            %    tempMean = step3means(:, 1);
            %    pred_x = [tempMean(1:end - 2); 0; 0];
            %    this.uHat = [0; 0];
            %else
                new_x = step4means(:, 2);
                new_cov = step4covs(:, :, 2);
                % pred_x = step3means(:, 2);
                nNeurons = length(this.neuronParametersHat(:, 1));
                
                this.neuronParametersHat = ...
                    reshape(new_x(1:3 * nNeurons), 3, nNeurons)';
                this.pos = [new_x(end - 3); new_x(end - 2)];
                this.uHat = [new_x(end - 1); new_x(end)];
                if(strcmp(this.covReset, 'no'))
                    this.cov = new_cov;
                elseif(strcmp(this.covReset, 'yes'))
                    this.cov = ...
                        blkdiag(new_cov(1:3 * nNeurons, 1:3 * nNeurons), ...
                        this.initialCursorCov);
                end
            %end
            
            this.oldDiscreteStateProbDist = step6;
            this.oldContinuousStateMean = step4means;
            this.oldContinuousStateCov = step4covs;
        end
        
        function [] = newTrial(this)
            this.pos = randomStartLocation();
            this.uHat = [0; 0];
            nNeurons = length(this.neuronParametersHat(:, 1));
            this.cov = blkdiag(this.cov(1:3 * nNeurons, 1:3 * nNeurons), ...
                this.initialCursorCov);
            this.timeStep = 0;
            
            this.oldDiscreteStateProbDist = ...
                this.initialDiscreteStateProbDist;
            flatten = @(x)x(:);
            this.oldContinuousStateMean = repmat( ...
               [feval(flatten, this.neuronParametersHat'); this.pos; ...
               this.uHat], 1, 2);
            this.oldContinuousStateCov = repmat(this.cov, [1 1 2]);
        end
        
        function [] = setNeuronParameters(this, newPars)
            this.neuronParametersHat = newPars;
            flatten = @(x)x(:);
            this.oldContinuousStateMean = repmat( ...
               [feval(flatten, this.neuronParametersHat'); this.pos; ...
               this.uHat], 1, 2);
        end
        
        function mat = matrixValue(this, name)
            if(ndims(this.matMap(name)) == 2)
                mat = this.matMap(name);
            else
                matList = this.matMap(name);
                mat = matList(:, :, this.timeStep);
            end
        end
    end
    
end
